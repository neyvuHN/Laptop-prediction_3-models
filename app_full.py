import io
import joblib
import numpy as np
import pandas as pd
import streamlit as st
import matplotlib.pyplot as plt
from pathlib import Path
from typing import Dict, Tuple, Optional, List

# Scikit-learn imports
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.impute import SimpleImputer
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import OneHotEncoder, StandardScaler

# Optional imports
try:
    from xgboost import XGBRegressor
except ImportError:
    XGBRegressor = None

try:
    from lightgbm import LGBMRegressor
except ImportError:
    LGBMRegressor = None

# =========================
# 1. C·∫§U H√åNH & H√ÄM H·ªñ TR·ª¢
# =========================

# Tham s·ªë t·ªëi ∆∞u (Best params) - ƒê·∫∑t l√†m m·∫∑c ƒë·ªãnh
BEST_PARAMS = {
    "RandomForestRegressor": {"n_estimators": 1000, "max_depth": 20},
    "XGBoostRegressor": {"n_estimators": 2000, "learning_rate": 0.03, "max_depth": 8},
    "LightGBMRegressor": {"n_estimators": 3000, "learning_rate": 0.03, "num_leaves": 31}
}

def load_data(default_dir: Path, train_up, val_up, test_up) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    def _read_csv(uploaded, fallback_path: Path) -> pd.DataFrame:
        if uploaded is not None: return pd.read_csv(uploaded)
        if fallback_path.exists(): return pd.read_csv(fallback_path)
        return pd.DataFrame() 

    df_train = _read_csv(train_up, default_dir / "data_train.csv")
    df_val = _read_csv(val_up, default_dir / "data_validation.csv")
    df_test = _read_csv(test_up, default_dir / "data_test.csv")
    return df_train, df_val, df_test

def train_and_eval(X_train, y_train, X_val, y_val, model_name, params):
    # T·ª± ƒë·ªông ph√¢n lo·∫°i c·ªôt s·ªë v√† c·ªôt ch·ªØ
    num_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()
    cat_cols = X_train.select_dtypes(exclude=[np.number]).columns.tolist()

    # Pipeline x·ª≠ l√Ω s·ªë: ƒêi·ªÅn d·ªØ li·ªáu thi·∫øu b·∫±ng trung v·ªã -> Chu·∫©n h√≥a
    numeric_pipe = Pipeline([
        ("imputer", SimpleImputer(strategy="median")),
        ("scaler", StandardScaler()) 
    ])

    # Pipeline x·ª≠ l√Ω ch·ªØ: ƒêi·ªÅn thi·∫øu -> One-Hot Encode (t·ª± ƒë·ªông bi·∫øn 'Intel' th√†nh vector)
    categorical_pipe = Pipeline([
        ("imputer", SimpleImputer(strategy="most_frequent")),
        ("onehot", OneHotEncoder(handle_unknown="ignore", sparse_output=False))
    ])

    preprocessor = ColumnTransformer([
        ("num", numeric_pipe, num_cols),
        ("cat", categorical_pipe, cat_cols),
    ], remainder="drop", verbose_feature_names_out=False)

    # Kh·ªüi t·∫°o Model
    if model_name == "RandomForestRegressor":
        model = RandomForestRegressor(n_jobs=-1, random_state=42, **params)
    elif model_name == "XGBoostRegressor":
        model = XGBRegressor(n_jobs=-1, random_state=42, **params)
    elif model_name == "LightGBMRegressor":
        model = LGBMRegressor(random_state=42, **params)
    
    # Gh√©p to√†n b·ªô th√†nh 1 Pipeline
    pipe = Pipeline([("preprocess", preprocessor), ("model", model)])
    
    # Train
    pipe.fit(X_train, y_train)
    
    # Eval
    y_pred = pipe.predict(X_val)
    metrics = {
        "MAE": mean_absolute_error(y_val, y_pred),
        "RMSE": np.sqrt(mean_squared_error(y_val, y_pred)),
        "R2": r2_score(y_val, y_pred)
    }
    return pipe, metrics, y_pred

# =========================
# 2. GIAO DI·ªÜN STREAMLIT
# =========================
st.set_page_config(page_title="Laptop Price Predictor", layout="wide", page_icon="üíª")
st.title("üíª H·ªá th·ªëng D·ª± b√°o Gi√° Laptop AI")

# --- SIDEBAR ---
with st.sidebar:
    st.header("1. D·ªØ li·ªáu")
    train_up = st.file_uploader("Upload Train", type=["csv"])
    val_up = st.file_uploader("Upload Validation", type=["csv"])
    test_up = st.file_uploader("Upload Test", type=["csv"])
    
    st.divider()
    st.header("2. Model & Hyperparameters")
    
    # Ch·ªçn Model
    avail_models = ["RandomForestRegressor"]
    if XGBRegressor: avail_models.append("XGBoostRegressor")
    if LGBMRegressor: avail_models.append("LightGBMRegressor")
    
    model_name = st.selectbox("Ch·ªçn thu·∫≠t to√°n", avail_models, index=len(avail_models)-1) # M·∫∑c ƒë·ªãnh ch·ªçn c√°i cu·ªëi (th∆∞·ªùng l√† LightGBM/XGB)
    
    # L·∫•y tham s·ªë m·∫∑c ƒë·ªãnh t·ªëi ∆∞u
    defaults = BEST_PARAMS.get(model_name, {})
    
    params = {}
    if model_name == "RandomForestRegressor":
        params["n_estimators"] = st.number_input("n_estimators", 100, 5000, defaults.get("n_estimators", 1000))
        params["max_depth"] = st.number_input("max_depth (0=None)", 0, 100, defaults.get("max_depth", 0))
        if params["max_depth"] == 0: params["max_depth"] = None
        
    elif model_name == "XGBoostRegressor":
        params["n_estimators"] = st.number_input("n_estimators", 100, 5000, defaults.get("n_estimators", 2000))
        params["learning_rate"] = st.number_input("learning_rate", 0.001, 1.0, defaults.get("learning_rate", 0.03), format="%.3f")
        params["max_depth"] = st.number_input("max_depth", 1, 20, defaults.get("max_depth", 8))
        
    elif model_name == "LightGBMRegressor":
        params["n_estimators"] = st.number_input("n_estimators", 100, 5000, defaults.get("n_estimators", 3000))
        params["learning_rate"] = st.number_input("learning_rate", 0.001, 1.0, defaults.get("learning_rate", 0.03), format="%.3f")
        params["num_leaves"] = st.number_input("num_leaves", 10, 200, defaults.get("num_leaves", 31))

    st.divider()
    train_btn = st.button("üöÄ Hu·∫•n luy·ªán Model", type="primary")

# --- X·ª¨ L√ù D·ªÆ LI·ªÜU ---
default_dir = Path(__file__).parent
df_train, df_val, df_test = load_data(default_dir, train_up, val_up, test_up)

TARGET = "price_base"
DROP_COLS = ["title", "link", "id", "product_url"] # C√°c c·ªôt kh√¥ng d√πng ƒë·ªÉ train

if "pipeline" not in st.session_state:
    st.session_state.pipeline = None
if "metrics" not in st.session_state:
    st.session_state.metrics = None

# --- TAB 1: HU·∫§N LUY·ªÜN ---
tab_train, tab_pred = st.tabs(["üß† Hu·∫•n luy·ªán & ƒê√°nh gi√°", "üîÆ D·ª± b√°o gi√° (Giao di·ªán chu·∫©n)"])

with tab_train:
    if train_btn:
        if df_train.empty or df_val.empty:
            st.error("Ch∆∞a c√≥ d·ªØ li·ªáu Train/Validation!")
        elif TARGET not in df_train.columns:
            st.error(f"Kh√¥ng t√¨m th·∫•y c·ªôt m·ª•c ti√™u '{TARGET}'.")
        else:
            with st.spinner("ƒêang hu·∫•n luy·ªán Pipeline (Encode -> Train)..."):
                # Chu·∫©n b·ªã d·ªØ li·ªáu
                cols_to_drop = [c for c in DROP_COLS if c in df_train.columns] + [TARGET]
                X_train = df_train.drop(columns=cols_to_drop, errors='ignore')
                y_train = df_train[TARGET]
                
                X_val = df_val.drop(columns=cols_to_drop, errors='ignore')
                y_val = df_val[TARGET]
                
                # L∆∞u danh s√°ch c·ªôt feature ƒë·ªÉ kh·ªõp l√∫c d·ª± ƒëo√°n
                st.session_state.feature_names = X_train.columns.tolist()
                
                # Train
                pipe, metrics, y_pred_val = train_and_eval(X_train, y_train, X_val, y_val, model_name, params)
                
                st.session_state.pipeline = pipe
                st.session_state.metrics = metrics
                st.success("Hu·∫•n luy·ªán xong!")
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    if st.session_state.metrics:
        m = st.session_state.metrics
        c1, c2, c3 = st.columns(3)
        c1.metric("MAE (Sai s·ªë)", f"{m['MAE']:,.0f} VNƒê")
        c2.metric("RMSE", f"{m['RMSE']:,.0f}")
        c3.metric("R2 Score", f"{m['R2']:.3f}")

# --- TAB 2: D·ª∞ B√ÅO (GIAO DI·ªÜN C≈® C·ª¶A B·∫†N) ---
with tab_pred:
    if st.session_state.pipeline is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng hu·∫•n luy·ªán model ·ªü Tab 1 tr∆∞·ªõc.")
    else:
        st.write("Nh·∫≠p th√¥ng s·ªë c·∫•u h√¨nh (Input th√¥ - Pipeline s·∫Ω t·ª± ƒë·ªông Encode):")
        
        with st.form("prediction_form"):
            t1, t2, t3 = st.tabs(["üöÄ C·∫•u h√¨nh l√µi", "üñ•Ô∏è M√†n h√¨nh", "üîã Pin & Kh√°c"])
            
            with t1:
                c1, c2, c3 = st.columns(3)
                cpu_cores = c1.number_input("S·ªë nh√¢n CPU", 2, 64, 8)
                cpu_threads = c2.number_input("S·ªë lu·ªìng CPU", 2, 128, 12)
                cpu_gen = c3.number_input("Th·∫ø h·ªá CPU (Gen)", 0, 14, 12)
                
                ram_size = c1.selectbox("RAM (GB)", [4, 8, 16, 32, 64, 128], index=2)
                # L∆∞u √Ω: Value c·ªßa selectbox ph·∫£i kh·ªõp v·ªõi d·ªØ li·ªáu trong file csv (vd: DDR4, DDR5)
                ram_type = c2.selectbox("Lo·∫°i RAM", ["DDR4", "DDR5", "DDR3", "LPDDR4", "LPDDR5", "Other"], index=0)
                storage_size = c3.number_input("SSD (GB)", 128, 8192, 512)
                
                cpu_brand = c1.radio("H√£ng CPU", ["Intel", "AMD", "Apple", "Other"], horizontal=True)
                gpu_vram = c2.selectbox("VRAM (GB)", [0, 2, 4, 6, 8, 12, 16, 24], index=2)
                gpu_class = c3.radio("Lo·∫°i GPU", ["Discrete", "Integrated", "Unknown"], horizontal=True)

            with t2:
                c1, c2, c3 = st.columns(3)
                screen_size = c1.number_input("K√≠ch th∆∞·ªõc (inch)", 10.0, 18.0, 15.6)
                brightness = c2.number_input("ƒê·ªô s√°ng (nits)", 200, 1000, 300)
                # True/False s·∫Ω ƒë∆∞·ª£c convert sang 1/0 ho·∫∑c gi·ªØ nguy√™n t√πy pipeline
                anti_glare = c3.toggle("Ch·ªëng ch√≥i (Anti-glare)", value=True)
                
                res_w = c1.number_input("ƒê·ªô ph√¢n gi·∫£i ngang (px)", 1280, 4000, 1920)
                res_h = c2.number_input("ƒê·ªô ph√¢n gi·∫£i d·ªçc (px)", 720, 3000, 1080)
                srgb = c3.slider("ƒê·ªô ph·ªß m√†u sRGB (%)", 45, 100, 65)

            with t3:
                c1, c2 = st.columns(2)
                brand_score = c1.slider("ƒêi·ªÉm th∆∞∆°ng hi·ªáu (Brand Score)", 0, 30, 20)
                gpu_brand = c2.selectbox("H√£ng GPU", ["NVIDIA", "AMD", "Intel", "Apple", "Other"])
                
                battery_wh = c1.number_input("Pin (Wh)", 30.0, 99.9, 50.0)
                battery_cells = c2.number_input("S·ªë Cell Pin", 2, 6, 3)

            submit = st.form_submit_button("üí∞ ƒê·ªäNH GI√Å NGAY")

        if submit:
            # 1. T·∫°o DataFrame t·ª´ Input th√¥ (Raw Data)
            # T√™n c·ªôt (keys) ph·∫£i TR√ôNG KH·ªöP v·ªõi t√™n c·ªôt trong file CSV hu·∫•n luy·ªán
            input_data = {
                'cpu_cores': cpu_cores,
                'cpu_threads': cpu_threads,
                'ram_size': ram_size,
                'storage_size': storage_size,
                'screen_size': screen_size,
                'cpu_gen': cpu_gen,
                'screen_brightness_nits': brightness,
                'screen_srgb_percent': srgb,
                'battery_wh': battery_wh,
                'battery_cells': battery_cells,
                'res_width': res_w,
                'res_height': res_h,
                'res_total_pixels': res_w * res_h,
                'gpu_vram': gpu_vram,
                'brand_score': brand_score,
                'screen_anti_glare': 1 if anti_glare else 0,
                'raw_specs_count': 25, # Gi√° tr·ªã placeholder n·∫øu c·∫ßn
                
                # C·ªôt d·∫°ng ch·ªØ (Category) - Pipeline s·∫Ω t·ª± lo One-Hot Encoding
                'ram_type': ram_type,
                'cpu_brand': cpu_brand,
                'gpu_brand': gpu_brand,   # Kh√¥ng c·∫ßn gpu_brand_te n·ªØa
                'gpu_class': gpu_class    # Kh√¥ng c·∫ßn gpu_class_te n·ªØa
            }
            
            # Chuy·ªÉn th√†nh DataFrame 1 d√≤ng
            input_df = pd.DataFrame([input_data])
            
            # L·ªçc ch·ªâ gi·ªØ l·∫°i c√°c c·ªôt m√† Model ƒë√£ h·ªçc (ƒë·ªÉ tr√°nh l·ªói th·ª´a c·ªôt)
            valid_cols = [c for c in st.session_state.feature_names if c in input_df.columns]
            
            # N·∫øu thi·∫øu c·ªôt n√†o ƒë√≥ (v√≠ d·ª• file train c√≥ c·ªôt 'weight' m√† form kh√¥ng c√≥) -> T·∫°o c·ªôt ƒë√≥ v·ªõi gi√° tr·ªã NaN
            missing_cols = set(st.session_state.feature_names) - set(input_df.columns)
            for c in missing_cols:
                input_df[c] = np.nan # Imputer trong pipeline s·∫Ω ƒëi·ªÅn gi√° tr·ªã n√†y
            
            # S·∫Øp x·∫øp l·∫°i c·ªôt cho ƒë√∫ng th·ª© t·ª±
            input_df = input_df[st.session_state.feature_names]

            # 2. D·ª± b√°o
            try:
                pred = st.session_state.pipeline.predict(input_df)[0]
                
                # T√≠nh kho·∫£ng gi√°
                mae = st.session_state.metrics['MAE']
                lower = pred - mae
                upper = pred + mae
                
                st.divider()
                c_kq1, c_kq2 = st.columns([1, 2])
                with c_kq1:
                    st.success("K·∫æT QU·∫¢ D·ª∞ B√ÅO")
                    st.metric("Gi√° trung b√¨nh", f"{pred:,.0f} ƒë")
                with c_kq2:
                    st.info(f"Kho·∫£ng gi√° tin c·∫≠y (¬±MAE):\n### {lower:,.0f} - {upper:,.0f} VNƒê")
                    
            except Exception as e:
                st.error(f"L·ªói khi d·ª± b√°o: {str(e)}")
                st.write("Vui l√≤ng ki·ªÉm tra l·∫°i t√™n c·ªôt trong file CSV c√≥ kh·ªõp v·ªõi form nh·∫≠p li·ªáu kh√¥ng.")
